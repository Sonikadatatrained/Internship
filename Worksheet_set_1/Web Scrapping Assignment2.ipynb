{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843fb166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e5b217",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.shine.com/\"\n",
    "response=requests.get(url)\n",
    "soup=BeautifulSoup(response.text,\"html.parser\")\n",
    "search_url=\"https://www.shine.com/job-search/data-analyst-jobs-in-bangalore-jobs-in-bangalore?q=data%20analyst%20jobs%20in%20bangalore&loc=Bangalore\"\n",
    "params={\"q\": \"Data Analyst\",\n",
    "    \"l\": \"Bangalore\"}\n",
    "response = requests.get(search_url, params=params)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "#scrape the data for the first 10 jobs results\n",
    "jobs=[]\n",
    "\n",
    "job_elements = soup.select(\".result-display__profile\")\n",
    "\n",
    "for job_elem in job_elements[:10]:\n",
    "    title_elem = job_elem.select_one(\".result-display__profile__job-title\")\n",
    "    company_elem = job_elem.select_one(\".result-display__profile__company-name\")\n",
    "    location_elem = job_elem.select_one(\".result-display__profile__location\")\n",
    "    experience_elem = job_elem.select_one(\".result-display__profile__experience\")\n",
    "    \n",
    "    \n",
    "    og:title = title_elem.get_text(strip=True) if title_elem else \"N/A\"\n",
    "    company_name = company_elem.get_text(strip=True) if company_elem else \"N/A\"\n",
    "    job_location = lovation_elem.get_text(Strip=True) if location_elem else \"N/A\"\n",
    "    experience = experience_elem.get_text(Strip=True) if experience_elem else \"N/A\"\n",
    "\n",
    "jobs.append({\n",
    "    \"Job Title\": og:title,\n",
    "    \"Company Name\": company_name,\n",
    "    \"Job Location\": job_location,\n",
    "    \"Experience\": experience\n",
    "            })\n",
    "    \n",
    "# Create a data Frame\n",
    "df=pd.DataFrame(jobs)\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4663cb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.shine.com/\"\n",
    "response=requests.get(url)\n",
    "soup=BeautifulSoup(response.text,\"html.parser\")\n",
    "search_url=\"https://www.shine.com/job-search/data-scientist-jobs-in-bangalore-jobs-in-bangalore?q=data%20scientist%20%20jobs%20in%20bangalore&loc=Bangalore\"\n",
    "params={\"query\": \"Data Scientist\",\n",
    "    \"loc\": \"Bangalore\"}\n",
    "response = requests.get(search_url, params=params)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "#scrape the data for the first 10 jobs results\n",
    "jobs=[]\n",
    "\n",
    "job_elements = soup.select(\".search_listing\")\n",
    "\n",
    "for job_elem in job_elements[:10]:\n",
    "    title_elem = job_elem.find(\"h2\")\n",
    "    company_elem = job_elem.find(\"span\", class_='company-name')\n",
    "    location_elem = job.elem.find(\"span\", class_=\"location\")\n",
    "    experience_elem = job.elem.find(\"li\", class_=\"experience\")\n",
    "    \n",
    "    \n",
    "    job_title = title_elem.get_text(strip=True) if title_elem else \"N/A\"\n",
    "    company_name = company_elem.get_text(strip=True) if company_elem else \"N/A\"\n",
    "    job_location = lovation_elem.get_text(Strip=True) if location_elem else \"N/A\"\n",
    "    experience = experience_elem.get_text(Strip=True) if experience_elem else \"N/A\"\n",
    "\n",
    "jobs.append({\n",
    "    \"Job Title\": job_title,\n",
    "    \"Company Name\": company_name,\n",
    "    \"Job Location\": job_location,\n",
    "    \"Experience\": experience\n",
    "            })\n",
    "    \n",
    "# Create a data Frame\n",
    "df=pd.DataFrame(jobs)\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750d6b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.shine.com/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "search_url = \"https://www.shine.com/job-search/data-scientist-jobs-in-delhi\"\n",
    "params = {\n",
    "    \"query\": \"Data Scientist\"\n",
    "}\n",
    "response = requests.get(search_url, params=params)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "location_filter = soup.find(\"label\", text=\"Location\")\n",
    "salary_filter = soup.find(\"label\", text=\"Salary\")\n",
    "location_filter_input = location_filter.find(\"input\")\n",
    "salary_filter_input = salary_filter.find(\"input\")\n",
    "location_filter_input[\"checked\"] = \"checked\"\n",
    "salary_filter_input[\"checked\"] = \"checked\"\n",
    "\n",
    "search_button = soup.select_one(\".button-jd\")\n",
    "response = requests.get(search_button[\"href\"])\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "jobs = []\n",
    "job_elements = soup.select(\".result-display__profile\")\n",
    "for job_elem in job_elements[:10]:\n",
    "    title_elem = job_elem.select_one(\".result-display__profile__job-title\")\n",
    "    company_elem = job_elem.select_one(\".result-display__profile__company-name\")\n",
    "    location_elem = job_elem.select_one(\".result-display__profile__location\")\n",
    "    experience_elem = job_elem.select_one(\".result-display__profile__experience\")\n",
    "    \n",
    "    job_title = title_elem.get_text(strip=True) if title_elem else \"N/A\"\n",
    "    company_name = company_elem.get_text(strip=True) if company_elem else \"N/A\"\n",
    "    job_location = location_elem.get_text(strip=True) if location_elem else \"N/A\"\n",
    "    experience_required = experience_elem.get_text(strip=True) if experience_elem else \"N/A\"\n",
    "\n",
    "    jobs.append({\n",
    "        \"Job Title\": job_title,\n",
    "        \"Company Name\": company_name,\n",
    "        \"Job Location\": job_location,\n",
    "        \"Experience Required\": experience_required\n",
    "    })\n",
    "    \n",
    "    df = pd.DataFrame(jobs)\n",
    "    df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa3659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = []\n",
    "descriptions = []\n",
    "prices = []\n",
    "for page in range(1, 6):  # Assuming 20 listings per page, 5 pages for 100 listings\n",
    "    url = f\"https://www.flipkart.com/search?q=sunglasses&page={page}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    for item in soup.select(\"._1AtVbE\"):\n",
    "        brand = item.select_one(\"._2WkVRV\").get_text(strip=True)\n",
    "        description = item.select_one(\"._2B099V > a\").get_text(strip=True)\n",
    "        price = item.select_one(\"._30jeq3\").get_text(strip=True)\n",
    "        \n",
    "        brands.append(brand)\n",
    "        descriptions.append(description)\n",
    "        prices.append(price)\n",
    "        \n",
    "        data = {\n",
    "    \"Brand\": brands,\n",
    "    \"Product Description\": descriptions,\n",
    "    \"Price\": prices\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d5b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = []\n",
    "review_summaries = []\n",
    "full_reviews = []\n",
    "\n",
    "for page in range(1, 11):\n",
    "    url = f\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART&page={page}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    for review in soup.select(\".col._2wzgFH\"):\n",
    "        rating = review.select_one(\"._3LWZlK\").get_text(strip=True)\n",
    "        review_summary = review.select_one(\"._2-N8zT\").get_text(strip=True)\n",
    "        full_review = review.select_one(\".t-ZTKy\").get_text(strip=True)\n",
    "        \n",
    "        ratings.append(rating)\n",
    "        review_summaries.append(review_summary)\n",
    "        full_reviews.append(full_review)\n",
    "        \n",
    "        data = {\n",
    "    \"Rating\": ratings,\n",
    "    \"Review Summary\": review_summaries,\n",
    "    \"Full Review\": full_reviews\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8baa09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = []\n",
    "descriptions = []\n",
    "prices = []\n",
    "for page in range(1, 4):\n",
    "    url = f\"https://www.flipkart.com/search?q=sneakers&page={page}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    for sneaker in soup.select(\".s1Q9rs\"):\n",
    "        brand = sneaker.select_one(\"div > div._2WkVRV\").get_text(strip=True)\n",
    "        description = sneaker.select_one(\"div > aIRwTa > img\")[\"alt\"]\n",
    "        price = sneaker.select_one(\"div > div._30jeq3\").get_text(strip=True)\n",
    "        \n",
    "        brands.append(brand)\n",
    "        descriptions.append(description)\n",
    "        prices.append(price)\n",
    "        \n",
    "        data = {\n",
    "    \"Brand\": brands,\n",
    "    \"Product Description\": descriptions,\n",
    "    \"Price\": prices\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5a71c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "ratings = []\n",
    "prices = []\n",
    "\n",
    "url = \"https://www.amazon.in/s?k=Laptop&rh=n%3A1375424031&fs=true&qid=1629139666&ref=sr_pg_1\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "for laptop in soup.select(\".s-result-item\"):\n",
    "    title = laptop.select_one(\"h2 a span\").get_text(strip=True)\n",
    "    \n",
    "    rating_element = laptop.select_one(\".a-icon-alt\")\n",
    "    rating = rating_element.get_text(strip=True) if rating_element else \"N/A\"\n",
    "    \n",
    "    price_element = laptop.select_one(\".a-price .a-offscreen\")\n",
    "    price = price_element.get_text(strip=True) if price_element else \"N/A\"\n",
    "    \n",
    "    titles.append(title)\n",
    "    ratings.append(rating)\n",
    "    prices.append(price)\n",
    "\n",
    "    if len(titles) >= 10:\n",
    "        break\n",
    "        \n",
    "        data = {\n",
    "    \"Title\": titles,\n",
    "    \"Ratings\": ratings,\n",
    "    \"Price\": prices\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d5f1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = []\n",
    "authors = []\n",
    "types = []\n",
    "url = \"https://www.azquotes.com/top_quotes.html\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "for quote in soup.select(\".quotes .title a\"):\n",
    "    quote_text = quote.get_text(strip=True)\n",
    "    quotes.append(quote_text)\n",
    "    \n",
    "    author = quote.find_next_sibling(\"div\", class_=\"author\").get_text(strip=True)\n",
    "    authors.append(author)\n",
    "    \n",
    "    quote_type = quote.find_next_sibling(\"div\", class_=\"type\").get_text(strip=True)\n",
    "    types.append(quote_type)\n",
    "\n",
    "    if len(quotes) >= 1000:\n",
    "        break\n",
    "\n",
    "# Create a DataFrame from the scraped data\n",
    "data = {\n",
    "    \"Quote\": quotes,\n",
    "    \"Author\": authors,\n",
    "    \"Type\": types\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ffd212",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "born_dead = []\n",
    "terms_of_office = []\n",
    "remarks = []\n",
    "url = \"https://www.jagranjosh.com/general-knowledge/list-of-prime-ministers-of-india-1441940815-1\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "for pm in soup.select(\".contentData tr\")[1:]:\n",
    "    columns = pm.select(\"td\")\n",
    "    \n",
    "    name = columns[0].get_text(strip=True)\n",
    "    names.append(name)\n",
    "    \n",
    "    born_dead_info = columns[1].get_text(strip=True)\n",
    "    born_dead.append(born_dead_info)\n",
    "    \n",
    "    term_of_office = columns[2].get_text(strip=True)\n",
    "    terms_of_office.append(term_of_office)\n",
    "    \n",
    "    remark = columns[3].get_text(strip=True)\n",
    "    remarks.append(remark)\n",
    "    \n",
    "    data = {\n",
    "    \"Name\": names,\n",
    "    \"Born-Dead\": born_dead,\n",
    "    \"Term of Office\": terms_of_office,\n",
    "    \"Remarks\": remarks\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4becc2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_names = []\n",
    "prices = []\n",
    "\n",
    "url = \"https://www.motor1.com/features/262079/most-expensive-cars-2018/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "for car in soup.select(\".slideshow-slide\"):\n",
    "    car_name = car.select_one(\".slide-title a\").get_text(strip=True)\n",
    "    car_names.append(car_name)\n",
    "    \n",
    "    price = car.select_one(\".slide-price\").get_text(strip=True)\n",
    "    prices.append(price)\n",
    "    \n",
    "    if len(car_names) >= 50:\n",
    "        break\n",
    "        \n",
    "        data = {\n",
    "    \"Car Name\": car_names,\n",
    "    \"Price\": prices\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297dd6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
